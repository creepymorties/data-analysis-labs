{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### О задании\n",
    "\n",
    "Практическое задание 1 посвящено изучению основных библиотек для анализа данных, а также линейных моделей и методов их обучения. Вы научитесь:\n",
    " * применять библиотеки NumPy и Pandas для осуществления желаемых преобразований;\n",
    " * подготавливать данные для обучения линейных моделей;\n",
    " * обучать линейную, Lasso и Ridge-регрессии при помощи модуля scikit-learn;\n",
    " * реализовывать обычный и стохастический градиентные спуски;\n",
    " * обучать линейную регрессию для произвольного функционала качества.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Библиотеки для анализа данных\n",
    "\n",
    "### NumPy\n",
    "\n",
    "Во всех заданиях данного раздела запрещено использовать циклы  и list comprehensions. Под вектором и матрицей в данных заданиях понимается одномерный и двумерный numpy.array соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Реализуйте функцию, возвращающую максимальный элемент в векторе x среди элементов, перед которыми стоит нулевой. Для x = np.array([6, 2, 0, 3, 0, 0, 5, 7, 0]) ответом является 5. Если нулевых элементов нет, функция должна возвращать None.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_arr = np.array([6, 2, 0, 3, 0, 0, 5, 7, 0])\n",
    "input_arr_no_zeroes = np.random.rand(0,10)\n",
    "\n",
    "\n",
    "def max_element(arr: np.ndarray):\n",
    "    \n",
    "    if len(arr[arr == 0]) == 0:\n",
    "        return None\n",
    "    \n",
    "    x = arr[np.insert(np.diff(input).astype(bool), 0, True)]\n",
    "    next_el = np.vectorize(lambda x: x + 1)\n",
    "    res = np.take(x, next_el(np.where(x == 0)[0]), mode='clip')\n",
    "    return np.max(res[res.nonzero()])\n",
    "\n",
    "print(max_element(input_arr))\n",
    "print(max_element(input_arr_no_zeroes))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. ** Реализуйте функцию, принимающую на вход матрицу и некоторое число и возвращающую ближайший к числу элемент матрицы. Например: для X = np.arange(0,10).reshape((2, 5)) и v = 3.6 ответом будет 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_arr = np.arange(0,10).reshape((2, 5))\n",
    "val = 9.3\n",
    "\n",
    "def nearest_value(x: np.ndarray, v: float):\n",
    "    diff_func = np.vectorize(lambda x: abs(x - v)) \n",
    "    return np.take(x, np.argmin(diff_func(x)))\n",
    "\n",
    "nearest_value(input_arr, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. ** Реализуйте функцию scale(X), которая принимает на вход матрицу и масштабирует каждый ее столбец (вычитает выборочное среднее и делит на стандартное отклонение). Убедитесь, что в функции не будет происходить деления на ноль. Протестируйте на случайной матрице (для её генерации можно использовать, например, функцию [numpy.random.randint](http://docs.scipy.org/doc/numpy/reference/generated/numpy.random.randint.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simple ndarray (matrix) to test with \n",
    "\n",
    "test_matrix = np.array([[0, 0], [0, 0], [1, 1], [1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [ 1.,  1.],\n",
       "       [ 1.,  1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scale(x: np.ndarray):\n",
    "    return (x - x.mean()) / x.std()\n",
    "\n",
    "scale(test_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Реализуйте функцию, которая для заданной матрицы находит:\n",
    " - определитель\n",
    " - след\n",
    " - наименьший и наибольший элементы\n",
    " - норму Фробениуса\n",
    " - собственные числа\n",
    " - обратную матрицу\n",
    "\n",
    "Для тестирования сгенерируйте матрицу с элементами из нормального распределения $\\mathcal{N}$(10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'determinant': -39.11033956921605,\n",
      " 'eigen_values': array([39.81156856, -1.045561  ,  0.77669785,  1.20970874]),\n",
      " 'frobenius_norm': 40.04638129350938,\n",
      " 'inversed': array([[ 0.28119916,  0.02687238, -0.61656905,  0.43339415],\n",
      "       [-1.81722597,  0.84247425,  0.50395438,  0.35857627],\n",
      "       [-0.50746704, -0.16613262,  0.66607332, -0.08761079],\n",
      "       [ 1.89921023, -0.61343763, -0.50569937, -0.60690553]]),\n",
      " 'max_el': 11.873064722749294,\n",
      " 'min_el': 8.157109290932926,\n",
      " 'trace': 40.752414146212885}\n"
     ]
    }
   ],
   "source": [
    "input_matrix = np.random.normal(10, 1, 16).reshape(4, 4)\n",
    "\n",
    "@dataclass\n",
    "class Stats:\n",
    "    def __init__(self, matrix: np.ndarray) -> None:\n",
    "        \n",
    "        self.determinant = np.linalg.det(matrix)\n",
    "        self.trace = np.trace(matrix)\n",
    "        self.max_el = np.max(matrix)\n",
    "        self.min_el = np.min(matrix)\n",
    "        self.frobenius_norm = np.linalg.norm(matrix)\n",
    "        self.eigen_values = np.linalg.eigvals(matrix)\n",
    "        self.inversed = np.linalg.inv(matrix)\n",
    "           \n",
    "\n",
    "def get_stats(x: np.ndarray):\n",
    "    return Stats(matrix=x)\n",
    "\n",
    "\n",
    "pprint(get_stats(input_matrix).__dict__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** Повторите 100 раз следующий эксперимент: сгенерируйте две матрицы размера 10×10 из стандартного нормального распределения, перемножьте их (как матрицы) и найдите максимальный элемент. Какое среднее значение по экспериментам у максимальных элементов? 95-процентная квантиль?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_mean': 8.70647550000318, 'quantile_95': 1.6293987019877694}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_els = []\n",
    "all_vals = []\n",
    "\n",
    "for exp_num in range(100):\n",
    "    mt1 = np.random.normal(size=100).reshape(10, 10)\n",
    "    mt2 = np.random.normal(size=100).reshape(10, 10)\n",
    "    \n",
    "    max_els.append(np.max(np.matmul(mt1, mt2)))\n",
    "    all_vals.extend(np.matrix.flatten(mt1).tolist())\n",
    "    all_vals.extend(np.matrix.flatten(mt2).tolist())\n",
    "    \n",
    "\n",
    "maxs_mean = np.mean(max_els)\n",
    "quantile_95 = np.quantile(all_vals, 0.95)\n",
    "\n",
    "\n",
    "pprint({'max_mean': maxs_mean, 'quantile_95': quantile_95})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas\n",
    "\n",
    "![](https://metrouk2.files.wordpress.com/2015/10/panda.jpg)\n",
    "\n",
    "#### Ответьте на вопросы о данных по авиарейсам в США за январь-апрель 2008 года.\n",
    "\n",
    "[Данные](https://www.dropbox.com/s/dvfitn93obn0rql/2008.csv?dl=0) и их [описание](http://stat-computing.org/dataexpo/2009/the-data.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('2008.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.** Какая из причин отмены рейса (`CancellationCode`) была самой частой? (расшифровки кодов можно найти в описании данных)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common CancellationCode is : A\n"
     ]
    }
   ],
   "source": [
    "df_cancellation_code_counted =  df['CancellationCode'].dropna().value_counts()\n",
    "most_common_code = df_cancellation_code_counted.where(df_cancellation_code_counted == df_cancellation_code_counted.max()).reset_index()['index'][0]\n",
    "print(f\"The most common CancellationCode is : {most_common_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.** Найдите среднее, минимальное и максимальное расстояние, пройденное самолетом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': 724.5082571428571, 'max': 4962, 'min': 31}\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class DistanceInfo:\n",
    "    def __init__(self, distance: pd.Series) -> None:\n",
    "        self.max = distance.max()\n",
    "        self.min = distance.min()\n",
    "        self.avg = distance.mean()\n",
    "    \n",
    "\n",
    "dist_info = DistanceInfo(df['Distance'])\n",
    "\n",
    "pprint(dist_info.__dict__)        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.** Не выглядит ли подозрительным минимальное пройденное расстояние? В какие дни и на каких рейсах оно было? Какое расстояние было пройдено этими же рейсами в другие дни?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      TailNum  Distance    Year  Month  DayofMonth\n",
      "1116   N795AS      31.0  2008.0   12.0        30.0\n",
      "6958   N795AS      31.0  2008.0   12.0        26.0\n",
      "17349  N768AS      31.0  2008.0    8.0        18.0\n",
      "27534  N764AS      31.0  2008.0    3.0        11.0\n",
      "46082  N708AS      31.0  2008.0    8.0         9.0\n",
      "48112  N762AS      31.0  2008.0    2.0        28.0\n"
     ]
    }
   ],
   "source": [
    "# Flights with min dist\n",
    "\n",
    "filter = df['Distance'] == dist_info.min\n",
    "min_dist_flights = df.where(filter).dropna(subset=['Distance'])\n",
    "pprint(min_dist_flights[['TailNum', 'Distance', 'Year', 'Month', 'DayofMonth']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Year  Month  DayofMonth  DayOfWeek  DepTime  CRSDepTime  ArrTime  \\\n",
      "84     2008      3          16          7   1332.0        1344   1419.0   \n",
      "994    2008      1           2          3   2359.0        2243    420.0   \n",
      "1116   2008     12          30          2   1123.0        1007   1148.0   \n",
      "1872   2008      1           1          2   1301.0        1328   1339.0   \n",
      "1951   2008     11          30          7   2025.0        2009   2147.0   \n",
      "...     ...    ...         ...        ...      ...         ...      ...   \n",
      "67275  2008      8          12          2   1007.0         958   1129.0   \n",
      "67631  2008      6          11          3   1314.0        1321   1358.0   \n",
      "67994  2008     10          30          4   1928.0        1845   2013.0   \n",
      "68514  2008      3          29          6    556.0         600    737.0   \n",
      "69107  2008      5           1          4    616.0         630    828.0   \n",
      "\n",
      "       CRSArrTime UniqueCarrier  FlightNum  ... TaxiIn  TaxiOut  Cancelled  \\\n",
      "84           1430            AS         61  ...    4.0     11.0          0   \n",
      "994           314            AS        164  ...    3.0      9.0          0   \n",
      "1116         1033            AS         65  ...    6.0      6.0          0   \n",
      "1872         1417            AS        152  ...    2.0      3.0          0   \n",
      "1951         2130            AS         52  ...    2.0      4.0          0   \n",
      "...           ...           ...        ...  ...    ...      ...        ...   \n",
      "67275        1127            AS        151  ...    4.0      5.0          0   \n",
      "67631        1411            AS         61  ...    4.0      6.0          0   \n",
      "67994        1933            AS         66  ...    4.0      4.0          0   \n",
      "68514         740            AS        151  ...    4.0     16.0          0   \n",
      "69107         820            AS        351  ...    5.0     20.0          0   \n",
      "\n",
      "       CancellationCode  Diverted  CarrierDelay WeatherDelay NASDelay  \\\n",
      "84                  NaN         0           NaN          NaN      NaN   \n",
      "994                 NaN         0          66.0          0.0      0.0   \n",
      "1116                NaN         0           0.0         75.0      0.0   \n",
      "1872                NaN         0           NaN          NaN      NaN   \n",
      "1951                NaN         0           0.0          0.0      1.0   \n",
      "...                 ...       ...           ...          ...      ...   \n",
      "67275               NaN         0           NaN          NaN      NaN   \n",
      "67631               NaN         0           NaN          NaN      NaN   \n",
      "67994               NaN         0           0.0          0.0      0.0   \n",
      "68514               NaN         0           NaN          NaN      NaN   \n",
      "69107               NaN         0           NaN          NaN      NaN   \n",
      "\n",
      "       SecurityDelay  LateAircraftDelay  \n",
      "84               NaN                NaN  \n",
      "994              0.0                0.0  \n",
      "1116             0.0                0.0  \n",
      "1872             NaN                NaN  \n",
      "1951             6.0               10.0  \n",
      "...              ...                ...  \n",
      "67275            NaN                NaN  \n",
      "67631            NaN                NaN  \n",
      "67994            0.0               40.0  \n",
      "68514            NaN                NaN  \n",
      "69107            NaN                NaN  \n",
      "\n",
      "[102 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "flights_to_find: np.ndarray = min_dist_flights['TailNum'].values\n",
    "flights_from_min_dist = df[df['TailNum'].isin(flights_to_find)]\n",
    "\n",
    "\n",
    "pprint(flights_from_min_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TailNum    Distance\n",
      "0  N708AS  660.500000\n",
      "1  N762AS  461.666667\n",
      "2  N764AS  398.600000\n",
      "3  N768AS  482.708333\n",
      "4  N795AS  758.000000\n"
     ]
    }
   ],
   "source": [
    "pprint(flights_from_min_dist.groupby(['TailNum'])['Distance'].mean().reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9.** Из какого аэропорта было произведено больше всего вылетов? В каком городе он находится?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Origin  TotalFlights\n",
      "0    ATL          4134\n"
     ]
    }
   ],
   "source": [
    "most_popular_airport = df.groupby(['Origin']).size().sort_values().tail(1).reset_index()\n",
    "most_popular_airport.columns.values[1] = 'TotalFlights'\n",
    "\n",
    "pprint(most_popular_airport)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10.** Найдите для каждого аэропорта среднее время полета (`AirTime`) по всем вылетевшим из него рейсам. Какой аэропорт имеет наибольшее значение этого показателя?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Origin    AirTime\n",
      "0      ABE  88.266667\n",
      "1      ABI  36.400000\n",
      "2      ABQ  93.454321\n",
      "3      ABY  35.714286\n",
      "4      ACK  50.800000\n",
      "..     ...        ...\n",
      "292    WRG  18.000000\n",
      "293    XNA  85.945736\n",
      "294    YAK  35.900000\n",
      "295    YKM  79.000000\n",
      "296    YUM  47.470588\n",
      "\n",
      "[297 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "mean_airtime_byairport = df.groupby(['Origin']).mean(['Airtime']).reset_index()[['Origin', 'AirTime']]\n",
    "pprint(mean_airtime_byairport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Origin</th>\n",
       "      <th>AirTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>SJU</td>\n",
       "      <td>205.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Origin  AirTime\n",
       "262    SJU    205.2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_airtime_byairport.sort_values(['AirTime']).dropna().tail(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11.** Найдите аэропорт, у которого наибольшая доля задержанных (`DepDelay > 0`) рейсов. Исключите при этом из рассмотрения аэропорты, из которых было отправлено меньше 1000 рейсов (используйте функцию `filter` после `groupby`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Origin  DepDelay\n",
      "117    ORD   60116.0\n"
     ]
    }
   ],
   "source": [
    "delays = df.groupby(['Origin']).filter(lambda x: x.size > 1000).groupby(['Origin']).sum().reset_index()[['Origin', 'DepDelay']]\n",
    "delays_pos = delays[delays['DepDelay'] > 0]\n",
    "max_delay = delays_pos.sort_values(['DepDelay']).dropna().tail(1)\n",
    "pprint(max_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Линейная регрессия\n",
    "\n",
    "В этой части мы разберемся с линейной регрессией, способами её обучения и измерением качества ее прогнозов. \n",
    "\n",
    "Будем рассматривать датасет из предыдущей части задания для предсказания времени задержки отправления рейса в минутах (DepDelay). Отметим, что под задержкой подразумевается не только опоздание рейса относительно планируемого времени вылета, но и отправление до планируемого времени.\n",
    "\n",
    "### Подготовка данных\n",
    "\n",
    "**12.** Считайте выборку из файла при помощи функции pd.read_csv и ответьте на следующие вопросы:\n",
    "   - Имеются ли в данных пропущенные значения?\n",
    "   - Сколько всего пропущенных элементов в таблице \"объект-признак\"?\n",
    "   - Сколько объектов имеют хотя бы один пропуск?\n",
    "   - Сколько признаков имеют хотя бы одно пропущенное значение?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы понимаете, также не имеет смысла рассматривать при решении поставленной задачи объекты с пропущенным значением целевой переменной. В связи с этим ответьте на следующие вопросы и выполните соответствующие действия:\n",
    "- Имеются ли пропущенные значения в целевой переменной?\n",
    "- Проанализируйте объекты с пропущенными значениями целевой переменной. Чем вызвано это явление? Что их объединяет? Можно ли в связи с этим, на ваш взгляд, исключить какие-то признаки из рассмотрения? Обоснуйте свою точку зрения.\n",
    "\n",
    "Исключите из выборки объекты **с пропущенным значением целевой переменной и со значением целевой переменной, равным 0**, а также при необходимости исключите признаки в соответствии с вашим ответом на последний вопрос из списка и выделите целевую переменную в отдельный вектор, исключив её из матрицы \"объект-признак\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**13.** Обратите внимание, что признаки DepTime, CRSDepTime, ArrTime, CRSArrTime приведены в формате hhmm, в связи с чем будет не вполне корректно рассматривать их как вещественные.\n",
    "\n",
    "Преобразуйте каждый признак FeatureName из указанных в пару новых признаков FeatureName\\_Hour, FeatureName\\_Minute, разделив каждое из значений на часы и минуты. Не забудьте при этом исключить исходный признак из выборки. В случае, если значение признака отсутствует, значения двух новых признаков, его заменяющих, также должны отсутствовать. \n",
    "\n",
    "Например, признак DepTime необходимо заменить на пару признаков DepTime_Hour, DepTime_Minute. При этом, например, значение 155 исходного признака будет преобразовано в значения 1 и 55 признаков DepTime_Hour, DepTime_Minute соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**14.** Некоторые из признаков, отличных от целевой переменной, могут оказывать чересчур значимое влияние на прогноз, поскольку по своему смыслу содержат большую долю информации о значении целевой переменной. Изучите описание датасета и исключите признаки, сильно коррелирующие с ответами. Ваш выбор признаков для исключения из выборки обоснуйте. Кроме того, исключите признаки TailNum и Year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**15.** Приведем данные к виду, пригодному для обучения линейных моделей. Для этого вещественные признаки надо отмасштабировать, а категориальные — привести к числовому виду. Также надо устранить пропуски в данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первую очередь поймем, зачем необходимо применять масштабирование. Следующие ячейки с кодом построят гистограммы для 3 вещественных признаков выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X['DepTime_Hour'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['TaxiIn'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['FlightNum'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какую проблему вы наблюдаете на этих графиках? Как масштабирование поможет её исправить?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые из признаков в нашем датасете являются категориальными. Типичным подходом к работе с ними является бинарное, или [one-hot-кодирование](https://en.wikipedia.org/wiki/One-hot).\n",
    "\n",
    "Реализуйте функцию transform_data, которая принимает на вход DataFrame с признаками и выполняет следующие шаги:\n",
    "1. Замена пропущенных значений на нули для вещественных признаков и на строки 'nan' для категориальных.\n",
    "2. Масштабирование вещественных признаков с помощью [StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html).\n",
    "3. One-hot-кодирование категориальных признаков с помощью [DictVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html) или функции [pd.get_dummies](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html).\n",
    "\n",
    "Метод должен возвращать преобразованный DataFrame, который должна состоять из масштабированных вещественных признаков и закодированных категориальных (исходные признаки должны быть исключены из выборки)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_data(data):\n",
    "    # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примените функцию transform_data к данным. Сколько признаков получилось после преобразования?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**16. (0.5 балла)** Разбейте выборку и вектор целевой переменной на обучение и контроль в отношении 70/30 (для этого можно использовать, например, функцию [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learn\n",
    "\n",
    "<img src = \"https://pp.vk.me/c4534/u35727827/93547647/x_d31c4463.jpg\">\n",
    "Теперь, когда мы привели данные к пригодному виду, попробуем решить задачу при помощи метода наименьших квадратов. Напомним, что данный метод заключается в оптимизации функционала $MSE$:\n",
    "\n",
    "$$MSE(X, y) = \\frac{1}{l} \\sum_{i=1}^l (<w, x_i> - y_i)^2 \\to \\min_{w},$$\n",
    "\n",
    "где $\\{ (x_i, y_i ) \\}_{i=1}^l$ — обучающая выборка, состоящая из $l$ пар объект-ответ.\n",
    "\n",
    "Заметим, что решение данной задачи уже реализовано в модуле sklearn в виде класса [LinearRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression).\n",
    "\n",
    "**17.** Обучите линейную регрессию на 1000 объектах из обучающей выборки и выведите значения $MSE$ и $R^2$ на этой подвыборке и контрольной выборке (итого 4 различных числа). Проинтерпретируйте полученный результат — насколько качественные прогнозы строит полученная модель? Какие проблемы наблюдаются в модели?\n",
    "\n",
    "**Подсказка**: изучите значения полученных коэффициентов $w$, сохраненных в атрибуте coef_ объекта LinearRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Для решения описанных вами в предыдущем пункте проблем используем L1- или L2-регуляризацию, тем самым получив Lasso и Ridge регрессии соответственно и изменив оптимизационную задачу одним из следующих образов:\n",
    "$$MSE_{L1}(X, y) = \\frac{1}{l} \\sum_{i=1}^l (<w, x_i> - y_i)^2 + \\alpha ||w||_1 \\to \\min_{w},$$\n",
    "$$MSE_{L2}(X, y) = \\frac{1}{l} \\sum_{i=1}^l (<w, x_i> - y_i)^2 + \\alpha ||w||_2^2 \\to \\min_{w},$$\n",
    "\n",
    "где $\\alpha$ — коэффициент регуляризации. Один из способов его подбора заключается в переборе некоторого количества значений и оценке качества на кросс-валидации для каждого из них, после чего выбирается значение, для которого было получено наилучшее качество.\n",
    "\n",
    "**18.** Обучите линейные регрессии с L1- и L2-регуляризатором, подобрав лучшее значение параметра регуляризации из списка alpha_grid при помощи кросс-валидации c 5 фолдами на тех же 1000 объектах, что и в п.17. Выведите значения $MSE$ и $R^2$ на обучающей и контрольной выборках. Удалось ли решить указанные вами ранее проблемы?\n",
    "\n",
    "Для выполнения данного задания вам могут понадобиться реализованные в библиотеке объекты [LassoCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html), [RidgeCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html) и [KFold](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.KFold.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиентный спуск\n",
    "\n",
    "В предыдущем разделе мы использовали существующие реализации методов обучения линейной регрессии с регуляризацией и без. Тем не менее, подобные реализации, как правило, имеются лишь для ограниченного набора стандартных методов. В частности, при выходе функционала качества за пределы стандартного множества необходимо самостоятельно реализовывать составляющие процесса решения оптимизационной задачи. Именно этому и посвящен данный раздел задания.\n",
    "\n",
    "Пусть необходимо минимизировать следующий функционал (Mean Square Percentage Error — модифицированный [RMSPE](https://www.kaggle.com/c/rossmann-store-sales/details/evaluation)):\n",
    "$$MSPE(\\{x_i, y_i\\}_{i=1}^l, \\, w) = \\frac{1}{l}\\sum_{i=1}^l \\left( \\frac{y_i - \\langle w, x_i \\rangle }{y_i} \\right)^2,$$\n",
    "\n",
    "где $\\{x_i, y_i\\}_{i=1}^l$ — обучающая выборка, $w$ — вектор весов линейной модели. Будем также рассматривать функционал $MSPE$ с L2-регуляризацией:\n",
    "\n",
    "$$MSPE(\\{x_i, y_i\\}_{i=1}^l, \\, w) = \\frac{1}{l}\\sum_{i=1}^l \\left( \\frac{y_i - \\langle w, x_i \\rangle }{y_i} \\right)^2 + ||w||_2^2.$$\n",
    "\n",
    "**19.** Добавьте к объектам обеих выборок из п. 16 единичный признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**20.** Реализуйте функции, которые вычисляют:\n",
    " * прогнозы линейной модели;\n",
    " * функционал $MSPE$ и его градиент;\n",
    " * регуляризованный $MSPE$ и его градиент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# возвращает вектор прогнозов линейной модели с вектором весов w для выборки X\n",
    "def make_pred(X, w):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# возвращает значение функционала MSPE для выборки (X, y) и вектора весов w\n",
    "def get_func(w, X, y):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# возвращает градиент функционала MSPE для выборки (X, y) и вектора весов w\n",
    "def get_grad(w, X, y):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# возвращает значение регуляризованного функционала MSPE для выборки (X, y) и вектора весов w\n",
    "def get_reg_func(w, X, y):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# возвращает градиент регуляризованного функционала MSPE для выборки (X, y) и вектора весов w\n",
    "def get_reg_grad(w, X, y):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**21.** Реализуйте метод градиентного спуска для описанных функционалов ($MSPE$ и его регуляризованный вариант). Функция должна принимать следующие параметры:\n",
    " - X — матрица \"объект-признак\";\n",
    " - y — вектор целевой переменной;\n",
    " - w0 — начальное значение вектора весов;\n",
    " - step_size — значение темпа обучения;\n",
    " - max_iter — максимальное число итераций;\n",
    " - eps — значение, используемое в критерии останова;\n",
    " - is_reg — бинарный параметр, принимает значение True в случае наличия регуляризации функционала, False — в противном случае.\n",
    " \n",
    "Процесс должен быть остановлен, если выполнено хотя бы одно из следующих условий:\n",
    " - было выполнено заданное количество итераций max_iter;\n",
    " - евклидова норма разности векторов $w$ на соседних итерациях стала меньше, чем eps.\n",
    "\n",
    "Функция должна возвращать полученный в результате оптимизации вектор $w$ и список значений функционала на каждой итерации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grad_descent(X, y, step_size, max_iter, eps, is_reg):\n",
    "    # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите линейную регрессию с функционалом $MSPE$ на обучающей выборке при помощи метода градиентного спуска и изобразите кривые зависимости значения функционала от номера итерации для различных:\n",
    " * значений размера шага из набора [0.001, 1, 10];\n",
    " * способов начальной инициализации вектора весов (нули, случайные веса).\n",
    "\n",
    "Проанализируйте полученные результаты — влияют ли данные параметры на скорость сходимости и итоговое качество? Если да, то как?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**22.** Обучите линейную регрессию с функционалом MSPE и его регуляризованным вариантом на обучающей выборке при помощи метода градиентного спуска и изобразите кривые зависимости значения функционала от номера итерации. Исследуйте зависимость скорости сходимости от наличия регуляризации. Обоснуйте, почему так происходит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод градиентного спуска может быть весьма трудозатратен в случае большого размера обучающей выборки. Поэтому часто используют метод стохастического градиентного спуска, где на каждой итерации выбирается случайный объект из обучающей выборки и обновление весов происходит только по этому объекту. \n",
    "\n",
    "**23.**  Реализуйте метод стохастического градиентного спуска (SGD) для описанных функционалов ($MSPE$ и его регуляризованный вариант). Функция должна иметь параметры и возвращаемое значение, аналогичные оным функции grad\\_descent из п.21. Кроме того, должен использоваться аналогичный критерий останова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sgd(X, y, step_size, max_iter, eps, is_reg):\n",
    "    # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите линейную регрессию с функционалом $MSPE$ и его регуляризованным вариантом на обучающей выборке при помощи метода стохастического градиентного спуска, подобрав при этом размер шага, при котором метод будет сходиться. Нарисуйте график сходимости. Выведите значения $MSPE, MSE, R^2$ на контрольной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**24.** Аналогично п.22 исследуйте зависимость скорости сходимости метода SGD от наличия регуляризации. Обоснуйте, почему так происходит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**25.** Обучите стандартную линейную регрессию с функционалом качества MSE на обучающей выборке и выведите значение MSPE полученного решения на контрольной выборке. Как оно соотносится с аналогичным результатом для решения, полученного в п.22? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6dfdbf814314f5228d869d148a99f3fdb55c68e76ee95238514a39cea5a1c1db"
  },
  "kernelspec": {
   "display_name": "HCIA_AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
